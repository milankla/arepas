# Arepas

[![CI](https://github.com/your-username/arepas/workflows/CI/badge.svg)](https://github.com/your-username/arepas/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

Arepas is a Python project for fine-tuning an AI model (OpenAI Vision) to categorize historical architectural buildings based on multiple attributes. The project features a high-performance data loading system that processes thousands of buildings with their associated images and architectural attributes.

## Features
- ğŸ—ï¸ **Enterprise-grade data loading architecture** with factory patterns and dependency injection
- ğŸš€ **High-performance image matching** (10-15x faster than original implementation)
- ğŸ“Š **Multi-neighborhood support** with automatic CSV file detection
- ğŸ”§ **Comprehensive validation** and error handling
- ğŸ“ˆ **Structured result objects** with rich metadata
- ğŸ¯ **Type-safe operations** throughout the codebase
- ğŸ” **Advanced logging** with configurable levels
- ğŸ“‹ **Configuration management** with environment auto-detection

## Current Dataset
- **8,208 buildings** across 6 neighborhoods (Cole, Regis, Skyland, South City Park, Sunnyside, Streetcar Commercial)
- **28,543 images** with 98.4% image coverage
- **Multiple architectural styles** including Bungalows and Minimal Traditional
- **Complex multi-CSV support** (e.g., Streetcar Commercial has 3 separate CSV files)

## Performance
- **1.0ms per building** average processing time
- **10-15x performance improvement** over original implementation
- **Enterprise-grade architecture** ready for production use

## Getting Started
1. Ensure you have Python 3.8+ installed.
2. (Recommended) Create a virtual environment:
   ```sh
   python3 -m venv .venv
   source .venv/bin/activate
   ```
3. Install dependencies:
   ```sh
   pip install -r requirements.txt
   ```
4. Run the main data loading pipeline:
   ```sh
   python -m src.fine_tune
   ```
5. (Optional) Test performance:
   ```sh
   python scripts/test_performance.py
   ```
6. (Optional) Try the enhanced API demo:
   ```sh
   python scripts/demo_enhanced_api.py
   ```

## Project Structure
```
ğŸ“¦ arepas/
â”œâ”€â”€ ğŸ¯ src/
â”‚   â”œâ”€â”€ loader/                    # Enterprise data loading system
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Package exports
â”‚   â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â”‚   â”œâ”€â”€ configurable_loader.py # JSON-driven data loader
â”‚   â”‚   â”œâ”€â”€ csv_parser.py         # Robust CSV parsing
â”‚   â”‚   â”œâ”€â”€ image_index.py        # High-performance image indexing
â”‚   â”‚   â””â”€â”€ load_config.py        # Configuration infrastructure
â”‚   â”œâ”€â”€ fine_tune.py              # Main pipeline entry point
â”‚   â”œâ”€â”€ log_config.py             # Logging configuration
â”‚   â””â”€â”€ preprocess.py             # Image preprocessing utilities
â”œâ”€â”€ ğŸ”§ scripts/
â”‚   â”œâ”€â”€ test_performance.py       # Performance benchmarking
â”‚   â”œâ”€â”€ demo_enhanced_api.py      # API demonstration
â”‚   â””â”€â”€ README.md                 # Scripts documentation
â”œâ”€â”€ ğŸ“ data/                      # Original attribute files
â”œâ”€â”€ ğŸ“ data2/                     # Images organized by neighborhood
â”œâ”€â”€ ï¿½ docs/                      # Technical documentation
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md      # Detailed architecture
â”‚   â”œâ”€â”€ RUNNING_FROM_COMMAND_LINE.md  # CLI usage guide
â”‚   â””â”€â”€ [6 more technical docs]
â””â”€â”€ ğŸ¯ requirements.txt           # Python dependencies
```

## Quick Usage

### Load All Neighborhoods
```python
from src.loader import ConfigurableDataLoader

# Load all datasets from configuration
loader = ConfigurableDataLoader('config/data2.json')
results = loader.load_all_datasets()

print(f"Loaded {len(results)} datasets")
# Access individual datasets: results['Cole'], results['Regis'], etc.
```

### Load Specific Neighborhood
```python
from src.loader import ConfigurableDataLoader

# Load data for a specific neighborhood
loader = ConfigurableDataLoader('config/data2.json')
result = loader.load_neighborhood('Cole')

# Access loaded data
print(f"Loaded {result.total_buildings} buildings")
print(f"Buildings with images: {result.buildings_with_images}")
print(f"Coverage: {result.coverage_percentage:.1f}%")

# Display summary
loader.print_summary()
```

## Architecture Highlights

### ğŸ—ï¸ **Enterprise Design Patterns**
- **JSON Configuration**: Declarative data structure mapping for maximum flexibility
- **Dependency Injection**: Configurable components for testing and flexibility
- **Single Responsibility**: Each module has a focused, well-defined purpose
- **Type Safety**: Comprehensive type hints throughout the codebase

### ğŸš€ **Performance Optimizations**
- **Image Index**: Pre-built hash tables for O(1) image lookups
- **Efficient Matching**: Street number extraction with minimal string operations
- **Memory Management**: Lazy loading and efficient data structures
- **Parallel Processing**: Ready for concurrent operations

### ğŸ“Š **Rich Result Objects**
- **Structured Data**: `LoadingResult`, `ImageMappingResult` with metadata
- **Error Handling**: Detailed error reporting with context
- **Statistics**: Built-in metrics and coverage analysis
- **Validation**: Input validation with clear error messages

## Development

### Running Tests
```sh
# Performance benchmarking
python scripts/test_performance.py

# API demonstration
python scripts/demo_enhanced_api.py
```

### Configuration
The system uses JSON configuration files for flexible data structure mapping:
```python
from src.loader import ConfigurableDataLoader

# Load using custom configuration
loader = ConfigurableDataLoader('config/custom_config.json')

# Or use predefined configurations
loader = ConfigurableDataLoader('config/data.json')   # Style-based structure
loader = ConfigurableDataLoader('config/data2.json')  # Neighborhood-based structure
```

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make your changes and test thoroughly
4. Submit a pull request

### Reporting Issues
- Use GitHub Issues for bug reports and feature requests
- Include detailed reproduction steps and environment info
- Check existing issues before creating new ones

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Built for processing historical architectural building data
- Optimized for Denver's architectural survey datasets
- Designed for OpenAI Vision fine-tuning workflows

## Notes
- **Production Ready**: Enterprise-grade architecture with comprehensive error handling
- **Scalable**: Designed to handle large datasets efficiently  
- **Maintainable**: Clear separation of concerns and extensive documentation
- **Type Safe**: Full type annotations for better IDE support and fewer bugs
